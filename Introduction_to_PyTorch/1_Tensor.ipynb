{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor\n",
    "\n",
    "텐서는 배열(array)이나 행렬(matrix)과 매우 유사한 특수한 자료구조이다. PyTorch에서는 텐서를 사용하여 모델의 입력(input)과 출력(output), 모델의 매개변수들을 부호화(encode)한다.\n",
    "\n",
    "1. 텐서는 GPU나 다른 하드웨어의 가속기에서만 실행이 가능하며, numpy의 ndarray와 유사하다. 실제로 텐서와 numpy 배열은 종종 동일한 내부(underly) 메모리를 공유할 수 있어 데이터를 복사할 필요가 없다.\n",
    "2. 텐서는 자동 미분(automatic defferentiation)에 최적화 되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 초기화\n",
    "\n",
    "**데이터로부터 직접(directly) 생성하기** \n",
    "\n",
    "데이터로부터 직접 텐서를 생성할 수 있으며, 데이터의 자료형(data type)은 자동으로 유추한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2], [3,4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**numpy 배열로부터 생성하기**\n",
    "\n",
    "텐서는 numpy 배열로 생성할 수 있으며, 반대도 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다른 텐서로부터 생성하기**\n",
    "\n",
    "명시적으로 재정의(override)하지 않는다면, 인자로 주어진 텐서의 속성(모양(shape), 자료형(datatype))을 유지한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor : \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor : \n",
      " tensor([[0.8726, 0.5537],\n",
      "        [0.4764, 0.5706]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)           # x_data의 속성을 유지함\n",
    "print(f\"Ones Tensor : \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)    # x_data의 속성을 덮어씀\n",
    "print(f\"Random Tensor : \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**무작위(random) 또는 상수(constant) 값을 사용하기**\n",
    "\n",
    "shape은 텐서의 차원(dimension)을 나타내는 튜플(tuple)로, 아래 함수들에서는 출력 텐서의 차원을 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor : \n",
      " tensor([[0.8011, 0.1341, 0.7963],\n",
      "        [0.3364, 0.4473, 0.5920]]) \n",
      "\n",
      "Ones Tensor : \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor : \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor : \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor : \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor : \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 속성(Attribute)\n",
    "\n",
    "텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor : torch.Size([3, 4])\n",
      "Datatype of tensor : torch.float32\n",
      "Device of tensor : cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor : {tensor.shape}\")\n",
    "print(f\"Datatype of tensor : {tensor.dtype}\")\n",
    "print(f\"Device of tensor : {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 연산(Operation)\n",
    "\n",
    "전치(transposing), 인덱싱(indexing), 슬라이싱(slicing), 수학 계산, 선형 대수, random sampling 등, 100가지 이상의 텐서 연산들을 확인할 수 있다.\n",
    "각 연산들은 GPU에서 실행할 수 있다. 기본적으로 텐서는 CPU에 생성된다. .to 메소드를 사용하면 GPU로 텐서를 명시적으로 이동할 수 있다.\n",
    "장치들 간에 큰 텐서들을 복사하는 것은 시간과 메모리 측면에서 비용이 많이 든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU가 존재하면 텐서를 이동한다.\n",
    "if torch.cuda.is_available() :\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**numpy식의 표준 인덱싱과 슬라이싱**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row : tensor([1., 1., 1., 1.])\n",
      "First cloumn : tensor([1., 1., 1., 1.])\n",
      "Last column : tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row : {tensor[0]}\")\n",
    "print(f\"First cloumn : {tensor[:, 0]}\")\n",
    "print(f\"Last column : {tensor[..., -1]}\")\n",
    "\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**텐서 합치기**\n",
    "\n",
    "<code>torch.cat</code>을 사용하여 주어진 차원에 따라 일련의 텐서를 연결할 수 있다. <code>torch.cat</code>과 미묘하게 다른 또 다른 텐서 결합 연산으로 <code>torch.stack</code>도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**산술 연산(Arithmetic operations)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산한다. y1, y2, y3는 모두 같은 값을 갖는다.\n",
    "# 'tensor.T'는 텐서의 전치(transpose)를 반환한다.\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "# 요소별 곱(element-wise product)을 계산한다. z1, z2, z3는 모두 같은 값을 갖는다.\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**단일-요소(single-element) 텐서**\n",
    "\n",
    "텐서의 모든 값을 하나로 집계(aggregate)하여 요소가 하나인 텐서의 경우, <code>item()</code>을 사용하여 Python 숫자값으로 변환할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**바꿔치기(in-place) 연산**\n",
    "\n",
    "연산 결과를 피연산자(operand)에 저장하는 연산을 바꿔치기 연산이라고 부르며, <code>_</code> 접미사를 갖는다.\n",
    "\n",
    "EX <code>x.copy_(y)</code>나 <code>x.t_()</code>는 <code>x</code>를 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**주의사항**\n",
    "\n",
    "바꿔치기 연산은 메모리를 일부 절약하지만, 기록이 즉시 삭제되어 도함수(derivative) 계산에 문제가 발생할 수 있으므로, 사용을 권장하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy 변환(Bridge)\n",
    "CPU 상태의 텐서와 numpy 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경된다.\n",
    "\n",
    "### 텐서를 NumPy 배열로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t : tensor([1., 1., 1., 1., 1.])\n",
      "n : [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t : {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n : {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t : tensor([2., 2., 2., 2., 2.])\n",
      "n : [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t : {t}\")\n",
    "print(f\"n : {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy 배열을 텐서로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t : tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n : [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t : {t}\")\n",
    "print(f\"n : {n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
